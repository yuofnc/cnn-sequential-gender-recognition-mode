{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom glob import glob\nimport os\nimport PIL\nimport tensorflow as tf\nimport pathlib \nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.python.keras.layers import Input,Dense,Flatten,Add,GlobalAveragePooling2D,Conv2D,SeparableConv2D,Add,LeakyReLU,MaxPooling2D,Activation,Dropout,BatchNormalization\n","metadata":{"execution":{"iopub.status.busy":"2023-02-17T06:29:41.468224Z","iopub.execute_input":"2023-02-17T06:29:41.468495Z","iopub.status.idle":"2023-02-17T06:29:46.448278Z","shell.execute_reply.started":"2023-02-17T06:29:41.468466Z","shell.execute_reply":"2023-02-17T06:29:46.447469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/biggest-genderface-recognition-dataset/faces'\nall_faces = glob('../input/biggest-genderface-recognition-dataset/faces/*/*')\nprint(len(all_faces))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T06:29:46.449901Z","iopub.execute_input":"2023-02-17T06:29:46.450156Z","iopub.status.idle":"2023-02-17T06:29:47.076233Z","shell.execute_reply.started":"2023-02-17T06:29:46.450121Z","shell.execute_reply":"2023-02-17T06:29:47.075470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nnum_classes = 2\nimg_height = 80\nimg_width = 80","metadata":{"execution":{"iopub.status.busy":"2023-02-17T06:29:50.777465Z","iopub.execute_input":"2023-02-17T06:29:50.777740Z","iopub.status.idle":"2023-02-17T06:29:50.781510Z","shell.execute_reply.started":"2023-02-17T06:29:50.777711Z","shell.execute_reply":"2023-02-17T06:29:50.780734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  '../input/biggest-genderface-recognition-dataset/faces',\n  validation_split=0.25,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T06:29:55.138241Z","iopub.execute_input":"2023-02-17T06:29:55.138519Z","iopub.status.idle":"2023-02-17T06:30:12.194434Z","shell.execute_reply.started":"2023-02-17T06:29:55.138488Z","shell.execute_reply":"2023-02-17T06:30:12.193663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n   '../input/biggest-genderface-recognition-dataset/faces',\n  validation_split=0.25,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T06:30:16.003831Z","iopub.execute_input":"2023-02-17T06:30:16.004463Z","iopub.status.idle":"2023-02-17T06:30:22.552591Z","shell.execute_reply.started":"2023-02-17T06:30:16.004427Z","shell.execute_reply":"2023-02-17T06:30:22.551816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\n#normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n\n\n#normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(train_ds))\nfirst_image = image_batch[0]\n# Notice the pixels values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T06:30:26.731689Z","iopub.execute_input":"2023-02-17T06:30:26.732270Z","iopub.status.idle":"2023-02-17T06:33:02.166420Z","shell.execute_reply.started":"2023-02-17T06:30:26.732227Z","shell.execute_reply":"2023-02-17T06:33:02.165595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata_augmentation = keras.Sequential(\n  [\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n                                                 input_shape=(img_height, \n                                                              img_width,\n                                                              3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-17T06:33:40.615172Z","iopub.execute_input":"2023-02-17T06:33:40.615451Z","iopub.status.idle":"2023-02-17T06:33:40.740496Z","shell.execute_reply.started":"2023-02-17T06:33:40.615421Z","shell.execute_reply":"2023-02-17T06:33:40.739584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nprint(type(train_ds))\nprint(train_ds)\narray = np.asarray(train_ds)\nprint(type(array))\nprint(array.shape)\n#(trainx,trainy) = array\n\n#print(trainx.shape)\n#print(trainy.shape)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-14T03:55:50.184781Z","iopub.execute_input":"2023-02-14T03:55:50.185049Z","iopub.status.idle":"2023-02-14T03:55:50.191433Z","shell.execute_reply.started":"2023-02-14T03:55:50.185022Z","shell.execute_reply":"2023-02-14T03:55:50.190561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=6,\n        width_shift_range=0.1, \n        height_shift_range=0.1,\n        horizontal_flip=True\n        )\n\ntrain_generator = train_datagen.flow_from_directory(\n        data_path,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='binary')\n\n\nnumber_of_examples = len(train_generator.filenames)\nnumber_of_generator_calls = int(number_of_examples / (1.0 * batch_size)) \nif (batch_size*number_of_generator_calls<number_of_examples):\n    number_of_generator_calls = number_of_generator_calls + 1\nprint('proc count:',number_of_generator_calls)    \n# 1.0 above is to skip integer division\n\ntrainx = []\ntrainy = []\ntrainx = np.array(trainx)\ntrainy = np.array(trainy)\nmcount = 0\niproc =10\nfor i in range(0,int(iproc)):\n    \n    #trainx.extend(np.array(train_generator[i][0]))\n    #trainy.extend(np.array(train_generator[i][1]))\n    if i==0:\n        trainx = np.array(train_generator[i][0])\n        trainy = np.array(train_generator[i][1])\n    else:\n        trainx = np.concatenate((trainx,np.array(train_generator[i][0])),axis = 0)\n        trainy = np.concatenate((trainy,np.array(train_generator[i][1])),axis = 0)\n    #trainy = np.concatenate((trainy,np.array(train_generator[i][1]))\n    mcount = mcount+1\n    if (mcount%10==9):\n        print('now proc:',mcount)\nprint(type(trainx))\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-14T04:14:04.456696Z","iopub.execute_input":"2023-02-14T04:14:04.456960Z","iopub.status.idle":"2023-02-14T04:14:22.880495Z","shell.execute_reply.started":"2023-02-14T04:14:04.456932Z","shell.execute_reply":"2023-02-14T04:14:22.879754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print((trainx.shape))","metadata":{"execution":{"iopub.status.busy":"2023-02-14T04:14:32.797207Z","iopub.execute_input":"2023-02-14T04:14:32.797472Z","iopub.status.idle":"2023-02-14T04:14:32.803728Z","shell.execute_reply.started":"2023-02-14T04:14:32.797445Z","shell.execute_reply":"2023-02-14T04:14:32.803020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(data_path,\n                                                               validation_split=0.25,\n                                                               subset=\"training\",\n                                                               seed=123,\n                                                               label_mode = 'int',\n                                                               image_size=(img_height, img_width),\n                                                               batch_size=batch_size)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(data_path,\n                                                               validation_split=0.25,\n                                                               subset=\"validation\",\n                                                               seed=123,\n                                                               label_mode = 'int',\n                                                               image_size=(img_height, img_width),\n                                                               batch_size=batch_size)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-14T06:45:45.250788Z","iopub.execute_input":"2023-02-14T06:45:45.251472Z","iopub.status.idle":"2023-02-14T06:46:03.758997Z","shell.execute_reply.started":"2023-02-14T06:45:45.251429Z","shell.execute_reply":"2023-02-14T06:46:03.758231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrainx = np.load('trainx.npy')\ntrainy = np.load('trainy.npy')\nprint(trainx.shape)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-14T06:05:51.532801Z","iopub.execute_input":"2023-02-14T06:05:51.533106Z","iopub.status.idle":"2023-02-14T06:06:07.851449Z","shell.execute_reply.started":"2023-02-14T06:05:51.533060Z","shell.execute_reply":"2023-02-14T06:06:07.850613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#not use\n\n\n'''\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=6,\n        width_shift_range=0.1, \n        height_shift_range=0.1,\n        horizontal_flip=True\n        )\n\ntrain_generator = train_datagen.flow_from_directory(\n        data_path,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='binary')\n\n'''\n\nnumber_of_examples = 27167 -6791\nnumber_of_generator_calls = int(number_of_examples / (1.0 * batch_size)) \nif (batch_size*number_of_generator_calls<number_of_examples):\n    number_of_generator_calls = number_of_generator_calls + 1\nprint('proc count:',number_of_generator_calls)    \n# 1.0 above is to skip integer division\n\ntrainx = []\ntrainy = []\ntrainx = np.array(trainx)\ntrainy = np.array(trainy)\nmcount = 0\niproc =int(number_of_generator_calls)\nfor i in range(0,int(iproc)):\n    for images, labels in train_ds.take(1):\n        if i==0:\n            trainx = np.array(images)\n            trainy = np.array(labels)\n        else:\n            trainx = np.concatenate((trainx,np.array(images)),axis = 0)\n            trainy = np.concatenate((trainy,np.array(labels)),axis = 0)\n    mcount = mcount+1\n    if (mcount%10==9):\n        print('now proc:',mcount)\n#trainx = np.array(trainx)\n#trainy = np.array(trainy)\nprint(type(trainx))\n'''\nindex=np.arange(iproc*batch_size)\nnp.random.shuffle(index)\nprint(index[0:20])\nprint(trainx.shape)\n\n\ntrainx=trainx[index,:,:,:]#X_train是训练集，y_train是训练标签\ntrainy=trainy[index]\n'''\nnp.save('trainx.npy',trainx)\nnp.save('trainy.npy',trainy)\nprint(trainx.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T06:34:31.450696Z","iopub.execute_input":"2023-02-14T06:34:31.450969Z","iopub.status.idle":"2023-02-14T06:39:55.242526Z","shell.execute_reply.started":"2023-02-14T06:34:31.450941Z","shell.execute_reply":"2023-02-14T06:39:55.241569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#not use\nnumber_of_examples = 6791\nnumber_of_generator_calls = int(number_of_examples / (1.0 * batch_size)) \nif (batch_size*number_of_generator_calls<number_of_examples):\n    number_of_generator_calls = number_of_generator_calls + 1\nprint('proc count:',number_of_generator_calls)    \n# 1.0 above is to skip integer division\n\ntestx = []\ntesty = []\ntestx = np.array(testx)\ntesty = np.array(testy)\nmcount = 0\niproc =int(number_of_generator_calls)\nfor i in range(0,int(iproc)):\n    for images, labels in val_ds.take(1):\n        if i==0:\n            testx = np.array(images)\n            testy = np.array(labels)\n        else:\n            testx = np.concatenate((testx,np.array(images)),axis = 0)\n            testy = np.concatenate((testy,np.array(labels)),axis = 0)\n    mcount = mcount+1\n    if (mcount%10==9):\n        print('now proc:',mcount)\n#trainx = np.array(trainx)\n#trainy = np.array(trainy)\nprint(type(testx))\n'''\nindex=np.arange(iproc*batch_size)\nnp.random.shuffle(index)\nprint(index[0:20])\nprint(trainx.shape)\n\n\ntrainx=trainx[index,:,:,:]#X_train是训练集，y_train是训练标签\ntrainy=trainy[index]\n'''\nnp.save('testx.npy',testx)\nnp.save('testy.npy',testy)\nprint(testx.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T06:40:22.083546Z","iopub.execute_input":"2023-02-14T06:40:22.083817Z","iopub.status.idle":"2023-02-14T06:41:47.214374Z","shell.execute_reply.started":"2023-02-14T06:40:22.083788Z","shell.execute_reply":"2023-02-14T06:41:47.212986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainx = np.load('trainx.npy')\ntrainy = np.load('trainy.npy')\ntestx  = np.load('testx.npy')\ntesty  = np.load('testy.npy')\nprint(trainx.shape)\n\nprint(trainy.shape)\nprint(testy.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:00:06.191632Z","iopub.execute_input":"2023-02-14T07:00:06.191933Z","iopub.status.idle":"2023-02-14T07:00:16.483027Z","shell.execute_reply.started":"2023-02-14T07:00:06.191900Z","shell.execute_reply":"2023-02-14T07:00:16.482194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrainx = []\ntrainy = []\nmcount = 0\niproc =int(number_of_generator_calls/2)\nfor i in range(iproc,int(number_of_generator_calls)):\n    trainx.extend(np.array(train_generator[i][0]))\n    trainy.extend(np.array(train_generator[i][1]))\n    mcount = mcount+1\n    if (mcount%10==9):\n        print('now proc:',mcount)\nicount = len(trainx)\ntrainx = np.array(trainx)\ntrainy = np.array(trainy)\nindex=np.arange(icount)\nnp.random.shuffle(index)\nprint(index[0:20])\nprint(trainx.shape)\n\n\ntrainx=trainx[index,:,:,:]#X_train是训练集，y_train是训练标签\ntrainy=trainy[index]\n\nnp.save('trainx2.npy',trainx)\nnp.save('trainy2.npy',trainy)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-13T06:11:50.582124Z","iopub.execute_input":"2023-02-13T06:11:50.582530Z","iopub.status.idle":"2023-02-13T06:13:09.724482Z","shell.execute_reply.started":"2023-02-13T06:11:50.582489Z","shell.execute_reply":"2023-02-13T06:13:09.723427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nx1 = np.load('trainx1.npy')\nprint(x1.shape)\nx2 = np.load('trainx2.npy')\nprint(x2.shape)\n#x1.append(np.array(x2))\nx1 = np.append(x1,x2)\ny1 = np.load('trainy1.npy')\ny2 = np.load('trainy2.npy')\n#y1.append(np.array(y2))\ny1 = np.append(y1,y2)\n\nx1 = x1.reshape(-1,180,180,3)\n\nprint(x1.shape)\nprint(y1.shape)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-13T06:14:52.866202Z","iopub.execute_input":"2023-02-13T06:14:52.866485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nindex=np.arange(len(train_generator.filenames))\nnp.random.shuffle(index)\nprint(index[0:20])\nprint(trainx.shape)\n\ntrainx=trainx[index,:,:,:]#X_train是训练集，y_train是训练标签\ntrainy=trainy[index]\n\nnp.save('trainx.npy',trainx)\nnp.save('trainy.npy',trainy)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-13T05:37:29.607461Z","iopub.execute_input":"2023-02-13T05:37:29.608190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntrainx = []\ntrainy = []\nstoplabel = False\nmcount =0\nfor i in range(10000):\n    for images, labels in train_ds.take(1):\n        if (len(images))>0:\n            trainx.append(images)\n            trainy.append(labels)\n        else:\n            stoplabel = True\n            break\n    if stoplabel:\n        break\n    mcount = mcount+1\n    if (mcount%10==9):\n        print('now proc:',mcount)\ntestx = []\ntesty = []\nstoplabel = False\nmcount =0\nfor i in range(10000):\n    for images, labels in val_ds.take(1):\n        if (len(images))>0:\n            testx.append(images)\n            testy.append(labels)\n        else:\n            stoplabel = True\n            break\n    if stoplabel:\n        break\n    mcount = mcount+1\n    if (mcount%10==9):\n        print('now proc:',mcount)\ntrainx = np.array(trainx)\ntrainy = np.array(trainy)\n\ntestx = np.array(testx)\ntesty = np.array(testy)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-13T04:38:34.083616Z","iopub.execute_input":"2023-02-13T04:38:34.083897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\n\nfor images, labels in train_ds.take(1):\n#print('image count:',len(trainx))\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        ax.imshow(images[i])\n        plt.title(labels[i])\n        plt.axis(\"off\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    print('image count:',len(images))\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        ax.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First CNN","metadata":{}},{"cell_type":"code","source":"'''\nmodel = Sequential([\n                  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3)),\n                  layers.Conv2D(16, 3, padding='same', activation='relu'),\n                  layers.MaxPooling2D(),\n                  layers.Conv2D(32, 3, padding='same', activation='relu'),\n                  layers.MaxPooling2D(),\n                  layers.Conv2D(64, 3, padding='same', activation='relu'),\n                  layers.MaxPooling2D(),\n                  layers.Dropout(0.5),\n                  layers.Flatten(),\n                  layers.Dense(128, activation='relu'),\n                  layers.Dense(num_classes, activation = 'sigmoid')\n])\n'''\n\nmodel = Sequential()\nmodel.add(data_augmentation),\nmodel.add(layers.experimental.preprocessing.Rescaling(1./255)),\nmodel.add(Conv2D(22,(3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.SeparableConv2D(60,3,activation='relu'))\nmodel.add(BatchNormalization())\n#model.add(Conv2D(64,(1,1), activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\n#model.add(Conv2D(64,(3,3), activation='relu'))\n#model.add(BatchNormalization())\n#model.add(layers.SeparableConv2D(128,3,activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Conv2D(90,(1,1),padding = 'same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\n#model.add(Conv2D(96,(3,3), activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(layers.SeparableConv2D(120,3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(196,(1,1),padding = 'same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(290,(3,3),padding = 'same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512,(3,3),padding = 'same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(960,(3,3),padding = 'same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.GlobalAveragePooling2D())\n\nmodel.add(layers.Dense(260,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(layers.Dense(120,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.Dense(num_classes))\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-17T06:15:35.957573Z","iopub.execute_input":"2023-02-17T06:15:35.957870Z","iopub.status.idle":"2023-02-17T06:15:36.339366Z","shell.execute_reply.started":"2023-02-17T06:15:35.957842Z","shell.execute_reply":"2023-02-17T06:15:36.338607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(data_augmentation),\nmodel.add(layers.experimental.preprocessing.Rescaling(1./255)),\nmodel.add(Conv2D(22,(3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.SeparableConv2D(60,3,activation='relu'))\nmodel.add(BatchNormalization())\n#model.add(Conv2D(64,(1,1), activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n#model.add(Conv2D(64,(3,3), activation='relu'))\n#model.add(BatchNormalization())\n#model.add(layers.SeparableConv2D(128,3,activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Conv2D(90,(1,1),padding = 'same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\n#model.add(Conv2D(96,(3,3), activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(layers.SeparableConv2D(120,3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(196,(1,1),padding = 'same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(BatchNormalization())\nmodel.add(layers.SeparableConv2D(290,3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.MaxPooling2D(2))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512,(3,3),padding = 'same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.SeparableConv2D(960,3,padding = 'same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(layers.GlobalAveragePooling2D())\n\nmodel.add(layers.Dense(260,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(layers.Dense(120,activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(layers.Dense(num_classes))\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-17T04:43:22.583947Z","iopub.execute_input":"2023-02-17T04:43:22.584665Z","iopub.status.idle":"2023-02-17T04:43:22.973373Z","shell.execute_reply.started":"2023-02-17T04:43:22.584611Z","shell.execute_reply":"2023-02-17T04:43:22.972612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n'''\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])\n'''","metadata":{"execution":{"iopub.status.busy":"2023-02-17T04:43:29.972622Z","iopub.execute_input":"2023-02-17T04:43:29.972915Z","iopub.status.idle":"2023-02-17T04:43:29.987752Z","shell.execute_reply.started":"2023-02-17T04:43:29.972879Z","shell.execute_reply":"2023-02-17T04:43:29.986772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                  patience=3,\n                                                  mode='min',\n                                                  restore_best_weights=True\n                                                 )\n\nfilepath = 'model_1.h5'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,\n                                                      monitor=\"val_loss\",\n                                                      save_best_only=True,\n                                                      save_weights_only=False,\n                                                      mode=\"min\",\n                                                      save_freq=\"epoch\",\n                                                    )\nfilepath2 = 'model_val_accuracy.h5'\nmodel_checkpoint2 = tf.keras.callbacks.ModelCheckpoint(filepath2,\n                                                      monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=False,\n                                                      mode= 'max',\n                                                      save_freq=\"epoch\",\n                                                    )","metadata":{"execution":{"iopub.status.busy":"2023-02-17T04:43:32.642517Z","iopub.execute_input":"2023-02-17T04:43:32.642783Z","iopub.status.idle":"2023-02-17T04:43:32.648827Z","shell.execute_reply.started":"2023-02-17T04:43:32.642753Z","shell.execute_reply":"2023-02-17T04:43:32.648151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = 'model_1.h5'\nmodel = load_model(save_path)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T06:27:17.982699Z","iopub.execute_input":"2023-02-14T06:27:17.983028Z","iopub.status.idle":"2023-02-14T06:27:18.253595Z","shell.execute_reply.started":"2023-02-14T06:27:17.982992Z","shell.execute_reply":"2023-02-14T06:27:18.252550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nhis =[]\n\nget_acc = []\nvalue_acc = []\nget_loss = []\nvalidation_loss = []\n#train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n#val_ds\nfor i in range(1,32):    \n    print('run times:',i)\n    '''\n    trainxPrev = trainx\n    if (i%3==1) : #or (i%3==2)\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=7,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.05)  # randomly flip images            \n        datagen.fit(trainxPrev)         \n    else:\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.03)  # randomly flip images            \n        datagen.fit(trainxPrev) \n    '''\n    his = model.fit(train_ds, validation_data = val_ds, epochs = epochs,\n                   verbose = 1, callbacks=[early_stopping, model_checkpoint,model_checkpoint2])\n    get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    value_acc+=(his.history['val_accuracy'])\n    get_loss+=(his.history['loss']) \n    validation_loss+=(his.history['val_loss']) \n        \n","metadata":{"execution":{"iopub.status.busy":"2023-02-17T04:43:37.277637Z","iopub.execute_input":"2023-02-17T04:43:37.277963Z","iopub.status.idle":"2023-02-17T04:54:59.202618Z","shell.execute_reply.started":"2023-02-17T04:43:37.277928Z","shell.execute_reply":"2023-02-17T04:54:59.201638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\n\n#train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n#val_ds\nfor i in range(1,60):    \n    print('run times:',i)\n    '''\n    trainxPrev = trainx\n    if (i%3==1) : #or (i%3==2)\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=7,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.05)  # randomly flip images            \n        datagen.fit(trainxPrev)         \n    else:\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.03)  # randomly flip images            \n        datagen.fit(trainxPrev) \n    '''\n    his = model.fit(train_ds, validation_data = val_ds, epochs = epochs,\n                   verbose = 1, callbacks=[early_stopping, model_checkpoint,model_checkpoint2])\n    get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    value_acc+=(his.history['val_accuracy'])\n    get_loss+=(his.history['loss']) \n    validation_loss+=(his.history['val_loss']) ","metadata":{"execution":{"iopub.status.busy":"2023-02-17T04:55:04.305424Z","iopub.execute_input":"2023-02-17T04:55:04.305710Z","iopub.status.idle":"2023-02-17T05:16:31.051116Z","shell.execute_reply.started":"2023-02-17T04:55:04.305681Z","shell.execute_reply":"2023-02-17T05:16:31.050393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\n\n#train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n#val_ds\nfor i in range(1,32):    \n    print('run times:',i)\n    '''\n    trainxPrev = trainx\n    if (i%3==1) : #or (i%3==2)\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=7,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.05)  # randomly flip images            \n        datagen.fit(trainxPrev)         \n    else:\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.03)  # randomly flip images            \n        datagen.fit(trainxPrev) \n    '''\n    his = model.fit(train_ds, validation_data = val_ds, epochs = epochs,\n                   verbose = 1, callbacks=[early_stopping, model_checkpoint,model_checkpoint2])\n    get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    value_acc+=(his.history['val_accuracy'])\n    get_loss+=(his.history['loss']) \n    validation_loss+=(his.history['val_loss']) ","metadata":{"execution":{"iopub.status.busy":"2023-02-14T09:41:47.032647Z","iopub.execute_input":"2023-02-14T09:41:47.032929Z","iopub.status.idle":"2023-02-14T09:53:54.566049Z","shell.execute_reply.started":"2023-02-14T09:41:47.032899Z","shell.execute_reply":"2023-02-14T09:53:54.565243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = model\nsave_path = 'model_val_accuracy.h5'\nmodel = load_model(save_path)\nmodel1_acc = model.evaluate(val_ds)[1]\nmodel1_acc","metadata":{"execution":{"iopub.status.busy":"2023-02-17T05:16:46.600313Z","iopub.execute_input":"2023-02-17T05:16:46.600591Z","iopub.status.idle":"2023-02-17T05:16:48.461478Z","shell.execute_reply.started":"2023-02-17T05:16:46.600561Z","shell.execute_reply":"2023-02-17T05:16:48.460749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    #get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    #value_acc+=(his.history['val_accuracy'])\n    #get_loss+=(his.history['loss']) \n    #validation_loss+=(his.history['val_loss']) \nimport matplotlib.pyplot as plt\nplt.plot(get_loss)\nplt.plot(validation_loss)\nplt.title('model loss')\nplt.ylabel('loss')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T05:16:54.243928Z","iopub.execute_input":"2023-02-17T05:16:54.244825Z","iopub.status.idle":"2023-02-17T05:16:54.453207Z","shell.execute_reply.started":"2023-02-17T05:16:54.244766Z","shell.execute_reply":"2023-02-17T05:16:54.452527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(get_acc)\nplt.plot(value_acc)\nplt.title('model Accuracy')\nplt.ylabel('Accuracy')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T05:16:57.347360Z","iopub.execute_input":"2023-02-17T05:16:57.347657Z","iopub.status.idle":"2023-02-17T05:16:57.572610Z","shell.execute_reply.started":"2023-02-17T05:16:57.347616Z","shell.execute_reply":"2023-02-17T05:16:57.571790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def modleEn():\n          \n        \n    En_input = Input(shape=(img_height, img_width,3), name='encoder_input')\n\n    x = En_input\n    x = data_augmentation(x)\n    x = layers.experimental.preprocessing.Rescaling(1./255)(x)\n\n    x_prev = x\n    x = Conv2D(\n                filters = 22\n                , kernel_size = 3\n                , strides = 1\n                , padding = 'same'                \n                )(x)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x)\n    \n    x = SeparableConv2D(filters = 60\n                , kernel_size = 3\n                , strides = 1)(x)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x)            \n\n    x = MaxPooling2D(2)(x)\n    x = BatchNormalization()(x)            \n    x = Dropout(0.2)(x)\n    \n    #model.add(Conv2D(64,(3,3), activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(layers.SeparableConv2D(128,3,activation='relu'))\n    #model.add(BatchNormalization())\n    \n    x = Conv2D(\n                filters = 90\n                , kernel_size = 1\n                , strides = 1\n                , padding = 'same'                \n                )(x)\n    x = BatchNormalization()(x)      \n    x = MaxPooling2D(2)(x)\n    x = BatchNormalization()(x)  \n    x = Dropout(0.1)(x)\n    \n    #model.add(Conv2D(96,(3,3), activation='relu'))\n    #model.add(BatchNormalization())\n    x = SeparableConv2D(filters = 120\n                , kernel_size = 3\n                , strides = 1)(x)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x) \n    \n    x = Conv2D(\n                filters = 196\n                , kernel_size = 1\n                , strides = 1\n                , padding = 'same'                \n                )(x)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x) \n    x = MaxPooling2D(2)(x)\n    x = BatchNormalization()(x) \n    \n    x = SeparableConv2D(filters = 290\n                , kernel_size = 3\n                , strides = 1)(x)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x) \n    \n    x = MaxPooling2D(2)(x)\n    \n    x = BatchNormalization()(x) \n\n    x = Conv2D(\n                filters = 512\n                , kernel_size = 3\n                , strides = 1\n                , padding = 'same'                \n                )(x)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x) \n    \n    x = SeparableConv2D(filters = 960\n                , kernel_size = 3\n                , strides = 1\n                , padding = 'same'\n                       )(x)                \n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x) \n    x = GlobalAveragePooling2D()(x) \n\n    x1 = x_prev\n    x1 = Conv2D(\n                filters = 32\n                , kernel_size = 3\n                , strides = 1\n                , padding = 'same'                \n                )(x1)\n    x1 = MaxPooling2D(2)(x1)\n    x1 = BatchNormalization()(x1) \n    x1 = Conv2D(\n                filters = 64\n                , kernel_size = 3\n                , strides = 1\n                , padding = 'same'                \n                )(x1)\n    x1 = MaxPooling2D(2)(x1)\n    x1 = BatchNormalization()(x1) \n    x1 = SeparableConv2D(filters = 128\n                , kernel_size = 3\n                , strides = 1\n                , padding = 'same'\n                       )(x1)                \n    x1 = MaxPooling2D(2)(x1)\n    x1 = BatchNormalization()(x1) \n    x1 = Conv2D(\n                filters = 256\n                , kernel_size = 3\n                , strides = 1\n                , padding = 'same'                \n                )(x1)\n    x1 = MaxPooling2D(2)(x1)\n    x1 = BatchNormalization()(x1)\n    x1 = LeakyReLU()(x1)\n    x1 = SeparableConv2D(filters = 960\n                , kernel_size = 3\n                , strides = 1\n                , padding = 'same'\n                       )(x1)                \n    x1 = LeakyReLU()(x1)\n    x1 = BatchNormalization()(x1) \n    x = Dropout(0.2)(x)\n    x1 = GlobalAveragePooling2D()(x1) \n    \n    x = Add()([x,x1])\n    x = Dense(260)(x)\n    x = LeakyReLU()(x)\n    x = BatchNormalization()(x) \n    x = Dropout(0.2)(x)\n    \n    x = Dense(120)(x)\n    x = LeakyReLU()(x)\n    \n    x = Dense(num_classes)(x)\n\n\n    modle = Model( En_input, x)\n    return modle","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:04:03.082677Z","iopub.execute_input":"2023-02-17T07:04:03.082976Z","iopub.status.idle":"2023-02-17T07:04:03.109227Z","shell.execute_reply.started":"2023-02-17T07:04:03.082943Z","shell.execute_reply":"2023-02-17T07:04:03.107799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = modleEn()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:04:08.763718Z","iopub.execute_input":"2023-02-17T07:04:08.764011Z","iopub.status.idle":"2023-02-17T07:04:09.221999Z","shell.execute_reply.started":"2023-02-17T07:04:08.763979Z","shell.execute_reply":"2023-02-17T07:04:09.221190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:04:16.935445Z","iopub.execute_input":"2023-02-17T07:04:16.935709Z","iopub.status.idle":"2023-02-17T07:04:16.948627Z","shell.execute_reply.started":"2023-02-17T07:04:16.935681Z","shell.execute_reply":"2023-02-17T07:04:16.947924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                  patience=3,\n                                                  mode='min',\n                                                  restore_best_weights=True\n                                                 )\n\nfilepath = 'model_5.h5'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,\n                                                      monitor=\"val_loss\",\n                                                      save_best_only=True,\n                                                      save_weights_only=False,\n                                                      mode=\"min\",\n                                                      save_freq=\"epoch\",\n                                                    )\nfilepath2 = 'model5_val_accuracy.h5'\nmodel_checkpoint2 = tf.keras.callbacks.ModelCheckpoint(filepath2,\n                                                      monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=False,\n                                                      mode= 'max',\n                                                      save_freq=\"epoch\",\n                                                    )","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:04:19.863364Z","iopub.execute_input":"2023-02-17T07:04:19.863626Z","iopub.status.idle":"2023-02-17T07:04:19.870527Z","shell.execute_reply.started":"2023-02-17T07:04:19.863597Z","shell.execute_reply":"2023-02-17T07:04:19.869611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nhis =[]\n\nget_acc = []\nvalue_acc = []\nget_loss = []\nvalidation_loss = []\n#train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n#val_ds\nfor i in range(1,60):    \n    print('run times:',i)\n    '''\n    trainxPrev = trainx\n    if (i%3==1) : #or (i%3==2)\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=7,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.05)  # randomly flip images            \n        datagen.fit(trainxPrev)         \n    else:\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.03)  # randomly flip images            \n        datagen.fit(trainxPrev) \n    '''\n    his = model.fit(train_ds, validation_data = val_ds, epochs = epochs,\n                   verbose = 1, callbacks=[early_stopping, model_checkpoint,model_checkpoint2])\n    get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    value_acc+=(his.history['val_accuracy'])\n    get_loss+=(his.history['loss']) \n    validation_loss+=(his.history['val_loss']) \n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:04:24.807313Z","iopub.execute_input":"2023-02-17T07:04:24.808146Z","iopub.status.idle":"2023-02-17T07:29:34.832779Z","shell.execute_reply.started":"2023-02-17T07:04:24.808099Z","shell.execute_reply":"2023-02-17T07:29:34.832048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nhis =[]\n\nget_acc = []\nvalue_acc = []\nget_loss = []\nvalidation_loss = []\n#train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n#val_ds\nfor i in range(1,60):    \n    print('run times:',i)\n    '''\n    trainxPrev = trainx\n    if (i%3==1) : #or (i%3==2)\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=7,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.05)  # randomly flip images            \n        datagen.fit(trainxPrev)         \n    else:\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.03)  # randomly flip images            \n        datagen.fit(trainxPrev) \n    '''\n    his = model.fit(train_ds, validation_data = val_ds, epochs = epochs,\n                   verbose = 1, callbacks=[early_stopping, model_checkpoint,model_checkpoint2])\n    get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    value_acc+=(his.history['val_accuracy'])\n    get_loss+=(his.history['loss']) \n    validation_loss+=(his.history['val_loss']) \n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:31:15.563171Z","iopub.execute_input":"2023-02-17T07:31:15.563455Z","iopub.status.idle":"2023-02-17T07:56:11.392732Z","shell.execute_reply.started":"2023-02-17T07:31:15.563425Z","shell.execute_reply":"2023-02-17T07:56:11.391730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model5 = model\nsave_path = 'model5_val_accuracy.h5'\nmodel = load_model(save_path)\nmodel5_acc = model.evaluate(val_ds)[1]\nmodel5_acc","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:56:19.967941Z","iopub.execute_input":"2023-02-17T07:56:19.968523Z","iopub.status.idle":"2023-02-17T07:56:22.439854Z","shell.execute_reply.started":"2023-02-17T07:56:19.968483Z","shell.execute_reply":"2023-02-17T07:56:22.439155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(get_loss)\nplt.plot(validation_loss)\nplt.title('model loss')\nplt.ylabel('loss')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:56:24.776725Z","iopub.execute_input":"2023-02-17T07:56:24.777320Z","iopub.status.idle":"2023-02-17T07:56:25.026767Z","shell.execute_reply.started":"2023-02-17T07:56:24.777283Z","shell.execute_reply":"2023-02-17T07:56:25.026069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(get_acc)\nplt.plot(value_acc)\nplt.title('model Accuracy')\nplt.ylabel('Accuracy')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T07:56:38.114136Z","iopub.execute_input":"2023-02-17T07:56:38.114447Z","iopub.status.idle":"2023-02-17T07:56:38.596465Z","shell.execute_reply.started":"2023-02-17T07:56:38.114417Z","shell.execute_reply":"2023-02-17T07:56:38.595724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(get_loss)\nplt.plot(validation_loss)\nplt.title('model loss')\nplt.ylabel('loss')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(get_acc)\nplt.plot(value_acc)\nplt.title('model Accuracy')\nplt.ylabel('Accuracy')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator \nfor i in range(1,30):    \n    print('run times:',i)\n    \n    trainxPrev = trainX\n    if (i%3==1) or (i%3==2):\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=True,  # apply ZCA whitening\n        rotation_range=7,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.45,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.45,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.23)  # randomly flip images            \n        datagen.fit(trainxPrev) \n    else:\n        datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=True,  # apply ZCA whitening\n        rotation_range=35,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,fill_mode='nearest',zoom_range=0.13)  # randomly flip images            \n        datagen.fit(trainxPrev) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Second CNN","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n                  data_augmentation,\n                  layers.experimental.preprocessing.Rescaling(1./255), #, input_shape=(img_height, img_width,3)\n                  layers.Conv2D(32, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.Conv2D(64, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.Conv2D(128, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.Conv2D(256, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.BatchNormalization(),\n                  layers.Dropout(0.06),\n                  layers.Flatten(),\n                  layers.Dense(256, activation='relu'),\n                  layers.Dense(num_classes, activation = 'sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:00:24.431767Z","iopub.execute_input":"2023-02-17T08:00:24.432545Z","iopub.status.idle":"2023-02-17T08:00:24.645270Z","shell.execute_reply.started":"2023-02-17T08:00:24.432508Z","shell.execute_reply":"2023-02-17T08:00:24.644524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:00:27.257590Z","iopub.execute_input":"2023-02-17T08:00:27.257876Z","iopub.status.idle":"2023-02-17T08:00:27.274317Z","shell.execute_reply.started":"2023-02-17T08:00:27.257827Z","shell.execute_reply":"2023-02-17T08:00:27.273121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:01:21.007557Z","iopub.execute_input":"2023-02-17T08:01:21.007927Z","iopub.status.idle":"2023-02-17T08:01:21.023801Z","shell.execute_reply.started":"2023-02-17T08:01:21.007879Z","shell.execute_reply":"2023-02-17T08:01:21.022870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                  patience=3,\n                                                  mode='min',\n                                                  restore_best_weights=True\n                                                 )\n\nfilepath = 'model_2.h5'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,\n                                                      monitor=\"val_loss\",\n                                                      save_best_only=True,\n                                                      save_weights_only=False,\n                                                      mode=\"min\",\n                                                      save_freq=\"epoch\",\n                                                    )\nfilepath2 = 'model2_val_accuracy.h5'\nmodel_checkpoint2 = tf.keras.callbacks.ModelCheckpoint(filepath2,\n                                                      monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=False,\n                                                      mode= 'max',\n                                                      save_freq=\"epoch\",\n                                                    )","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:01:23.614885Z","iopub.execute_input":"2023-02-17T08:01:23.615161Z","iopub.status.idle":"2023-02-17T08:01:23.621471Z","shell.execute_reply.started":"2023-02-17T08:01:23.615130Z","shell.execute_reply":"2023-02-17T08:01:23.620567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nhis =[]\n\nget_acc = []\nvalue_acc = []\nget_loss = []\nvalidation_loss = []\n#train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n#val_ds\nfor i in range(1,60):    \n    print('run times:',i)\n\n    his = model.fit(train_ds, validation_data = val_ds, epochs = epochs,\n                   verbose = 1, callbacks=[early_stopping, model_checkpoint,model_checkpoint2])\n    get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    value_acc+=(his.history['val_accuracy'])\n    get_loss+=(his.history['loss']) \n    validation_loss+=(his.history['val_loss']) ","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:02:14.335497Z","iopub.execute_input":"2023-02-17T08:02:14.336068Z","iopub.status.idle":"2023-02-17T08:07:14.469673Z","shell.execute_reply.started":"2023-02-17T08:02:14.336029Z","shell.execute_reply":"2023-02-17T08:07:14.468925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nfor i in range(1,60):    \n    print('run times:',i)\n\n    his = model.fit(train_ds, validation_data = val_ds, epochs = epochs,\n                   verbose = 1, callbacks=[early_stopping, model_checkpoint,model_checkpoint2])\n    get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    value_acc+=(his.history['val_accuracy'])\n    get_loss+=(his.history['loss']) \n    validation_loss+=(his.history['val_loss']) ","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:12:57.503269Z","iopub.execute_input":"2023-02-17T08:12:57.503541Z","iopub.status.idle":"2023-02-17T08:17:54.912489Z","shell.execute_reply.started":"2023-02-17T08:12:57.503512Z","shell.execute_reply":"2023-02-17T08:17:54.911607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = model\nsave_path = filepath2\nmodel = load_model(save_path)\nmodel2_acc = model.evaluate(val_ds)[1]\nmodel2_acc","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:18:01.259740Z","iopub.execute_input":"2023-02-17T08:18:01.260515Z","iopub.status.idle":"2023-02-17T08:18:02.379464Z","shell.execute_reply.started":"2023-02-17T08:18:01.260478Z","shell.execute_reply":"2023-02-17T08:18:02.378724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(get_loss)\nplt.plot(validation_loss)\nplt.title('model loss')\nplt.ylabel('loss')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:18:06.366063Z","iopub.execute_input":"2023-02-17T08:18:06.366336Z","iopub.status.idle":"2023-02-17T08:18:06.596519Z","shell.execute_reply.started":"2023-02-17T08:18:06.366305Z","shell.execute_reply":"2023-02-17T08:18:06.595741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(get_acc)\nplt.plot(value_acc)\nplt.title('model Accuracy')\nplt.ylabel('Accuracy')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:18:09.300210Z","iopub.execute_input":"2023-02-17T08:18:09.300491Z","iopub.status.idle":"2023-02-17T08:18:09.518172Z","shell.execute_reply.started":"2023-02-17T08:18:09.300460Z","shell.execute_reply":"2023-02-17T08:18:09.517427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Third CNN","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n                  data_augmentation,\n                  layers.experimental.preprocessing.Rescaling(1./255), #, input_shape=(img_height, img_width,3)\n                  layers.Conv2D(32, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.Conv2D(64, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.Conv2D(128, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.Dropout(0.06),\n                  layers.Conv2D(256, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.Dropout(0.1),\n                  layers.Conv2D(512, 3, padding='same', activation='relu'),\n                  layers.BatchNormalization(),\n                  layers.MaxPooling2D(),\n                  layers.BatchNormalization(),\n                  layers.Dropout(0.06),\n                  layers.Flatten(),\n                  layers.Dense(512, activation='relu'),\n                  layers.Dropout(0.06),  \n                  layers.Dense(300, activation = 'relu'),\n                  layers.Dense(num_classes, activation = 'sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:18:13.528624Z","iopub.execute_input":"2023-02-17T08:18:13.529206Z","iopub.status.idle":"2023-02-17T08:18:13.775199Z","shell.execute_reply.started":"2023-02-17T08:18:13.529167Z","shell.execute_reply":"2023-02-17T08:18:13.774453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:18:21.148588Z","iopub.execute_input":"2023-02-17T08:18:21.149011Z","iopub.status.idle":"2023-02-17T08:18:21.167421Z","shell.execute_reply.started":"2023-02-17T08:18:21.148960Z","shell.execute_reply":"2023-02-17T08:18:21.166687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:18:24.856577Z","iopub.execute_input":"2023-02-17T08:18:24.856860Z","iopub.status.idle":"2023-02-17T08:18:24.869830Z","shell.execute_reply.started":"2023-02-17T08:18:24.856815Z","shell.execute_reply":"2023-02-17T08:18:24.868923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                  patience=3,\n                                                  mode='min',\n                                                  restore_best_weights=True\n                                                 )\n\nfilepath = 'model_3.h5'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,\n                                                      monitor=\"val_loss\",\n                                                      save_best_only=True,\n                                                      save_weights_only=False,\n                                                      mode=\"min\",\n                                                      save_freq=\"epoch\",\n                                                    )\nfilepath3 = 'model3_val_accuracy.h5'\nmodel_checkpoint2 = tf.keras.callbacks.ModelCheckpoint(filepath3,\n                                                      monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=False,\n                                                      mode= 'max',\n                                                      save_freq=\"epoch\",\n                                                    )","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:18:29.567964Z","iopub.execute_input":"2023-02-17T08:18:29.568240Z","iopub.status.idle":"2023-02-17T08:18:29.574916Z","shell.execute_reply.started":"2023-02-17T08:18:29.568209Z","shell.execute_reply":"2023-02-17T08:18:29.573821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nhis =[]\n\nget_acc = []\nvalue_acc = []\nget_loss = []\nvalidation_loss = []\n#train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n#val_ds\nfor i in range(1,60):    \n    print('run times:',i)\n\n    his = model.fit(train_ds, validation_data = val_ds, epochs = epochs,\n                   verbose = 1, callbacks=[early_stopping, model_checkpoint,model_checkpoint2])\n    get_acc+=(his.history['accuracy']) \n    #print(get_acc)\n    value_acc+=(his.history['val_accuracy'])\n    get_loss+=(his.history['loss']) \n    validation_loss+=(his.history['val_loss']) ","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:18:37.266548Z","iopub.execute_input":"2023-02-17T08:18:37.266822Z","iopub.status.idle":"2023-02-17T08:24:25.840246Z","shell.execute_reply.started":"2023-02-17T08:18:37.266787Z","shell.execute_reply":"2023-02-17T08:24:25.839449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = model\nsave_path = filepath2\nmodel = load_model(save_path)\nmodel3_acc = model.evaluate(val_ds)[1]\nmodel3_acc","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:24:33.561758Z","iopub.execute_input":"2023-02-17T08:24:33.562540Z","iopub.status.idle":"2023-02-17T08:24:34.680294Z","shell.execute_reply.started":"2023-02-17T08:24:33.562504Z","shell.execute_reply":"2023-02-17T08:24:34.679557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:24:37.370573Z","iopub.execute_input":"2023-02-17T08:24:37.371152Z","iopub.status.idle":"2023-02-17T08:24:37.594587Z","shell.execute_reply.started":"2023-02-17T08:24:37.371115Z","shell.execute_reply":"2023-02-17T08:24:37.593911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model Accuracy')\nplt.ylabel('Accuracy')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:24:40.989020Z","iopub.execute_input":"2023-02-17T08:24:40.989309Z","iopub.status.idle":"2023-02-17T08:24:41.214429Z","shell.execute_reply.started":"2023-02-17T08:24:40.989278Z","shell.execute_reply":"2023-02-17T08:24:41.213707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = {'First_CNN' : model5_acc, 'Second_CNN' : model2_acc, 'Third_CNN' : model3_acc}\nresults","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:24:52.263508Z","iopub.execute_input":"2023-02-17T08:24:52.263780Z","iopub.status.idle":"2023-02-17T08:24:52.269870Z","shell.execute_reply.started":"2023-02-17T08:24:52.263750Z","shell.execute_reply":"2023-02-17T08:24:52.269032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing Results","metadata":{}},{"cell_type":"code","source":"plt.bar(results.keys(), results.values())\nplt.ylim(0.87, 0.9650)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T08:25:18.868114Z","iopub.execute_input":"2023-02-17T08:25:18.868380Z","iopub.status.idle":"2023-02-17T08:25:19.046478Z","shell.execute_reply.started":"2023-02-17T08:25:18.868350Z","shell.execute_reply":"2023-02-17T08:25:19.045730Z"},"trusted":true},"execution_count":null,"outputs":[]}]}